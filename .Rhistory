library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$Superplasticizer)
log(0)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
View(training)
names(training)
?preProcess
preProcess(training[c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")])
a <- preProcess(training[c("IL_11","IL_13","IL_16","IL_17E","IL_1alpha","IL_3","IL_4","IL_5","IL_6","IL_6_Receptor","IL_7","IL_8")])
a
summary(a)
rm(a)
View(training)
names(training)
a <- training[,c(1,58:69)]
View(a)
b <- abs(cor(a[,-1]))
diag(b) <- 0
which(b > 0.9,arr.ind=T)
View(b)
b
rm)b
rm(b)
preProc <- preProcess(log10(training[,-1]+1, method="pca", pcaComp=2))
preProc <- preProcess(log10(training[,-1]+1, method="pca", pcaComp=12))
preProc <- preProcess(training[,-1]+1, method="pca", pcaComp=2))
preProc <- preProcess(training[,-1]+1, method="pca", pcaComp=2)
?preProcess
preProcess(a)
View(a)
preProcess(a[,-1])
b <- preProcess(a[,-1])
summary(b)
b
ncol(training)
which(sapply(adData,class)=="factor")
summary(training$diagnosis)
training$diagnosis = as.numeric(training$diagnosis)
p <- prcomp(training[,grep('^IL',names(training))])
p$rotation[,1:7]
qplot(1:length(p$sdev),p$sdev / sum(p$sdev))
which(cumsum(p$sdev) / sum(p$sdev) <= .9)
(cumsum(p$sdev) / sum(p$sdev))[8]
#Result here
preProc <- preProcess(training[,grep('^IL',names(training))],method="pca",thres=.9)
preProc
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
rm(list=ls())
mtcars
df <- mtcars
inTrain = createDataPartition(df$mpg, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(mpg ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$mpg)
c1 <- confusionMatrix(predictions, testing$mpg)
c1 <- confusionMatrix(predictions, testing$mpg)
testing$mpg <- as.factor(testing$mpg)
predictions <- as.factor(predictions)
c1 <- confusionMatrix(predictions, testing$mpg)
rm(list=ls()
rm(list=ls())
df <- mtcars
df$mpg <- cut2(df$mpg)
View(df)
df <- mtcars
?cut2
df$mpg <- cut2(df$mpg,g=4)
df
inTrain = createDataPartition(df$mpg, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(mpg ~ ., method = "glm", data = training)
install.packages("e1071")
library(e1071)
modelFit <- train(mpg ~ ., method = "glm", data = training)
rm(list=ls())
df <- mtcars
inTrain <- createDataPartition(y=df$mpg, p=0.6, list=FALSE)
library(caret)
inTrain <- createDataPartition(y=df$mpg, p=0.6, list=FALSE)
training <- df[inTrain,]
testing <- df[-inTrain,]
modFit <- train(mpg~.,method="gbm",data=training,verbose=FALSE)
modFit <- train(mpg~.,method="gbm",data=training,verbose=FALSE)
modFit <- train(mpg~.,method="gbm",data=training,verbose=FALSE,tuneGrid = data.frame(mtry = 3))
modFit <- train(mpg~.,method="gbm",data=training,verbose=FALSE,tuneGrid = data.frame(mtry = 11))
modFit <- train(mpg~.,method="gbm",data=training,verbose=FALSE,tuneGrid = data.frame(mtry = 10))
modFit <- train(mpg~.,data=training,verbose=FALSE)
modFit <- train(mpg~.,data=training,verbose=FALSE)
modFit
qplot(predict(modFit,testing),mpg,data=testing)
lm(predict(modFit,testing),mpg,data=testing)
lm(mpg~predict(modFit,testing),data=testing)
lm <- lm(mpg~predict(modFit,testing),data=testing)
q <- qplot(predict(modFit,testing),mpg,data=testing)
q
q <- qplot(predict(modFit,testing),mpg,data=testing) + geom_smooth(lm)
?geom_smooth
q <- qplot(predict(modFit,testing),mpg,data=testing) + geom_smooth(lm)
q <- qplot(predict(modFit,testing),mpg,data=testing) + geom_smooth(method="lm")
q
df  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",stringsAsFactors=FALSE) ## import training data
a <- as.factor(df$classe) ## retain classe column as factor variable
df1 <- df[, !sapply(df, is.character)] ## remove character columns
df1$classe <- a; rm(a) ## add classe column back to training data
df2 <- df1[ , apply(df1, 2, function(x) !any(is.na(x)))] ## remove columns with NAs
fit <- summary(lm(classe~.,df2)) ## review coefficients
model <- train(classe~.,df2) ## train model
require(caret) ## package dependencies
model <- train(classe~.,df2) ## train model
createDataPartition((df2$classe,p=.05,list=FALSE))
createDataPartition(df2$classe,p=.05,list=FALSE)
sample <- createDataPartition(df2$classe,p=.05,list=FALSE)
sample df2[,sample]
sample df2[, sample]
sample <- df2[, sample]
sample <- df2[ ,sample]
sample <- df2[sample,]
model <- train(classe~.,sample) ## train model
model
model$finalModel
require(caret); require(ggplot2) ## package dependencies
require(caret); require(ggplot2) ## package dependencies
?qplot
qplot(classe,predict(model,df),data=df)## plot model against dependent variable classe
qplot(classe,predict(model,df),data=df) + geom_smooth(method="lm")## plot model against dependent variable classe
qplot(classe,predict(model,df2),data=df2) + geom_smooth(method="lm")## plot model against dependent variable classe
qplot(predict(model,classe,df),data=df) + geom_smooth(method="lm")## plot model against dependent variable classe
qplot(predict(model,df),classe,data=df) + geom_smooth(method="lm")## plot model against dependent variable classe
qplot(predict(model,df),classe,data=df,aes(group=1)) + geom_smooth(method="lm")## plot model against dependent variable classe
class(model)
model
rm(fit)
model
model$finalModel
test <- read.csv(https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
View(test)
?predict
predict(test,model)
predict(model)
extractPrediction(model, testX = test)
predict(model, newdata=test)
predict(model, newdata=df)
View(df)
View(test)
head(df)
test$classe
df&classes
df&classe
df$classe
predict(model, newdata=df)
View(test)
names(test)
predict(model, newdata=test)
a <- as.factor(test$classe) ## retain classe column as factor variable
df1 <- df[, !sapply(df, is.character)] ## remove character columns
df1$classe <- a; rm(a) ## add classe column back to training data
df2 <- df1[ , apply(df1, 2, function(x) !any(is.na(x)))] ## re
test1 <- test[, !sapply(test, is.character)]
test2 <- test1[ , apply(test1, 2, function(x) !any(is.na(x)))]
predict(model, newdata=test2)
nearZeroVar(df, saveMetrics=TRUE)
df1 <- df1[ , apply(df1, 2, function(x) !any(is.na(x)))] ## remove columns with NAs
rm(df2)
rm(test1,test2)
rm(a)
nearZeroVar(df1, saveMetrics=TRUE)
?nearZeroVar
print(confusionMatrix(model, df1$classe), digits=4)
confusionMatrix(model, df1$classe, digits=4)
confusionMatrix(model, df1$classe)
predict <- predict(model, newdata=df1) ## create prediction object
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1$classe, digits=4)
confusionMatrix(predict, df1$classe, digits=4)
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1$classe, digits=4)
print(confusionMatrix(predict, df1$classe, digits=4))
predict
class(predict)
predict <- predict(model, newdata=test) ## create prediction object
predict
print(confusionMatrix(predict, sample$classe, digits=4))
confusionMatrix(predict, df1$classe)
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1$classe)
length(predict)
confusionMatrix(predict, df1)
df1$classe
length(df1$classe)
df1$classe <- a; rm(a) ## add classe column back to training data
a <- as.factor(df$classe) ## retain classe column as factor variable
df1$classe <- a; rm(a) ## add classe column back to training data
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1)
confusionMatrix(predict, df1$classe)
print(predict(model, newdata=test))
predict <- predict(model, newdata=test) ## create prediction object
print(predict(model, newdata=test))
predict <- predict(model, newdata=test) ## create prediction object
predict
rm(sample)
?nearZeroVar
model1 <- model
rm(model)
rm(predict)
sample <- createDataPartition(df1,p=.01,list=FALSE); sample <- sample[,-sample]
sample <- createDataPartition(df1$classe,p=.01,list=FALSE); sample <- sample[,-sample]
sample <- createDataPartition(df1$classe,p=.01,list=FALSE); sample <- sample[,-sample]
sample <- createDataPartition(df1$classe,p=.01,list=FALSE); sample <- sample[,-sample]
l
sample <- createDataPartition(df1$classe,p=.01,list=FALSE); sample <- df1[,-sample]
sample <- createDataPartition(df1$classe,p=.01,list=FALSE)
sample <- df1[,-sample]
sample <- df1[-sample,]
sample <- createDataPartition(df1$classe,p=.01,list=FALSE)
sample <- df1[-sample,]
sample <- createDataPartition(df1$classe,p=.01,list=FALSE)
sample <- df1[sample,]
model <- train(classe~.,sample) ## train model
model$finalModel
model
predict <- predict(model, newdata=test) ## create prediction object
confusionMatrix(predict, df1$classe) ## call confusion matrix
confusionMatrix(predict, test$classe) ## call confusion matrix
predict
View(test)
model <- train(classe~.,sample, method="rpart") ## train model
model
predict <- predict(model, newdata=test) ## create prediction object
confusionMatrix(predict, test$classe) ## call confusion matrix
confusionMatrix(predict, test) ## call confusion matrix
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1) ## call confusion matrix
fancyRpartPlot(model$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(model$finalModel)
install.packages("rpart.plot")
library("rpart.plot")
library(rpart.plot)
fancyRpartPlot(model$finalModel)
View(df1)
df1 <- df1[,-1]
View(df1)
df1
mean(df1)
colMean(df1)
colmean(df1)
?colMeans
colMeans(df1)
df1 <- as.numeric(df1)
df1 <- as.numeric(col(df1)
df1 <- as.numeric(col(df1))
df1 <- df[, !sapply(df, is.character)] ## remove character columns
df1 <- df1[ , apply(df1, 2, function(x) !any(is.na(x)))] ## remove columns with NAs
df1 <- df1[,-1] ## remove "x" column
df1$classe <- a; rm(a) ## add classe column back to training data
sample <- createDataPartition(df1$classe,p=.01,list=FALSE);sample <- df1[sample,] ## create training data partition
nearZeroVar(df1, saveMetrics=TRUE) ## identify any near zero variance predictors
sample <- createDataPartition(df1$classe,p=.01,list=FALSE); sample <- df1[sample,] ## create training data partition
sample <- createDataPartition(df1$classe, p=.01,list=FALSE)
df1$classe
a <- as.factor(df$classe) ## retain classe column as factor variable
df1$classe <- a; rm(a) ## add classe column back to training data
sample <- createDataPartition(df1$classe, p=.01,list=FALSE); sample <- df1[sample,] ## create training data partition
model <- train(classe~.,sample, method="rpart") ## train model
fancyRpartPlot(model$finalModel)
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1) ## call confusion matrix
predict <- predict(model, newdata=test) ## create prediction object
confusionMatrix(predict, test) ## call confusion matrix
predict
qplot(predict(model,df1),classe,data=df1)## plot model against dependent variable classe
predict
model$finalModel
model
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, test$classe) ## call confusion matrix
confusionMatrix(predict, df1$classe) ## call confusion matrix
sample <- createDataPartition(df1$classe, p=.02,list=FALSE); sample <- df1[sample,] ## create training data partition
model <- train(classe~.,sample) ## train model (, method="rpart")??
model
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1$classe) ## call confusion matrix
predict <- predict(model, newdata=test) ## create prediction object
predict
sample <- createDataPartition(df1$classe, p=.03,list=FALSE); sample <- df1[sample,] ## create training data partition
model <- train(classe~.,sample, method="rpart") ## train model (, method="rpart")??
predict <- predict(model, newdata=test) ## create prediction object
predict
predict <- predict(model, newdata=df1) ## create prediction object
predict
confusionMatrix(predict, df1$classe) ## call confusion matrix
sample <- createDataPartition(df1$classe, p=.03,list=FALSE); sample <- df1[sample,] ## create training data partition
sample <- createDataPartition(df1$classe, p=.03,list=FALSE); sample <- df1[sample,] ## create training data partition
model <- train(classe~.,sample) ## train model
predict <- predict(model, newdata=df1) ## create prediction object
predict
confusionMatrix(predict, df1$classe) ## call confusion matrix
predict <- predict(model, newdata=test) ## create prediction object
predict
model
model$finalModel
model
model$finalModel ## show model stats including error rate
predict <- predict(model, newdata=df1) ## create prediction object
confusionMatrix(predict, df1$classe) ## call confusion matrix
model$finalModel ## show model stats including error rate
confusionMatrix(predict, df1$classe) ## call confusion matrix
str(df)
View(sample)
View(df)
rm(df1,sample,test,model,model1,predict)
rm(df)
training <- createDataPartition(df1$classe, p=.001,list=FALSE);testing <- df1[-training,]; training <- df1[training,]## create training and testing data partition using 5% of data for training
df  <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",stringsAsFactors=FALSE)
a <- as.factor(df$classe) ## retain classe column as factor variable "a"
?read.csv
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "df.csv") ## download data
a <- as.factor(df$classe) ## retain classe column as factor variable "a"
df1 <- df[, !sapply(df, is.character)] ## remove character columns from training data
df1 <- df1[ , apply(df1, 2, function(x) !any(is.na(x)))] ## remove all columns with NAs
df1 <- df1[,-1] ## remove "x" column
df1$classe <- a; rm(a) ## add classe column back to training data
require(caret) ## analysis dependencies
?nearZeroVar
require(caret) ## analysis dependencies
library(caret)
model <- train(classe ~ ., trControl = (trainControl(method = "repeatedcv", repeats = 3), sample) ## train model with cross-validation (10-fold with 3 repeats)
model <- train(classe~., trControl=(trainControl(method="repeatedcv", repeats=3), sample) ## train model with cross-validation (10-fold with 3 repeats)
model <- train(classe~., trControl=(trainControl(method="repeatedcv", repeats=3)), sample) ## train model with cross-validation (10-fold with 3 repeats)
model <- train(classe~., trControl=(trainControl(method="repeatedcv", repeats=3)), data=training) ## train model with cross-validation (10-fold with 3 repeats)
training <- createDataPartition(df1$classe, p=.001,list=FALSE);testing <- df1[-training,]; training <- df1[training,]## create training and testing data partition using 5% of data for training
model <- train(classe~., trControl=(trainControl(method="repeatedcv", repeats=3)), data=training) ## train model with cross-validation (10-fold with 3 repeats)
model <- train(classe~., trControl=(trainControl(method="repeatedcv", repeats=3)), data=training) ## train model with cross-validation (10-fold with 3 repeats)
model <- train(classe~., trControl=(trainControl(method="repeatedcv", repeats=3)), data=training) ## train model with cross-validation (10-fold with 3 repeats)
training <- createDataPartition(df1$classe, p=.05,list=FALSE);testing <- df1[-training,]; training <- df1[training,]## create training and testing data partition using 5% of data for training
training <- createDataPartition(df1$classe, p=.50,list=FALSE);testing <- df1[-training,]; training <- df1[training,]## create training and testing data partition using 5% of data for training
training <- createDataPartition(df1$classe, p=.60,list=FALSE);testing <- df1[-training,]; training <- df1[training,]## create training and testing data partition using 60% of data for training
model <- train(classe~., trControl=tc, data=training) ## train model with cross-validation (10-fold with 3 repeats)
tc <- trainControl(method="repeatedcv", repeats=3) ## set trainControl variable for cross-validation
model <- train(classe~., trControl=tc, data=training) ## train model with cross-validation (10-fold with 3 repeats)
nearZeroVar(df1, saveMetrics=TRUE) ## identify any near zero variance predictors
training <- createDataPartition(df1$classe, p=.60,list=FALSE);testing <- df1[-training,]; training <- df1[training,]## create training and testing data partition using 60% of data for training
tc <- trainControl(method="repeatedcv", repeats=3) ## set trainControl variable for cross-validation
model <- train(classe~., trControl=tc, data=training) ## train model with cross-validation (10-fold with 3 repeats)
write.table(model,model)
install_github('slidify'. 'ramnathv')
install_github('slidify', 'ramnathv')
library("devtools")
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library("slidify")
library(shiny)
rm(list=ls())
runApp()
runApp()
runApp()
?pageWithSidebar
?headerPanel
?shinyUI
?sidebarPanel
runApp()
?function
?function
f1  <- function(new) new / 100
f1(1000)
Age <- c(0:119)
Age
data <- read.csv("~/Data.xlsx")
data <- read.csv("Data.xlsx")
data <- read("Data.xlsx")
data <- read.table("Data.xlsx")
View(data)
data <- read.csv("Data.xlsx")
data <- read.csv("Data.xlsx")
data <- read.csv("Data.csv")
data <- read.csv("Data.csv")
data <- read.csv("Data.csv")
View(data)
Male <- data[,1]
Female <- data[,2]
rm(data)
Age
Male
Age <- c(0:119) ## create Age column for table
Male <- c(76.10, 75.62, 74.65, 73.67, 72.69, 71.70, 70.71, 69.72, 68.73, 67.74, 66.74, 65.75, 64.76, 63.76, 62.78, 61.80, 60.82, 59.86, 58.90, 57.95, 57.00, 56.06, 55.13, 54.20, 53.27, 52.34, 51.41, 50.48, 49.55, 48.62, 47.68, 46.75, 45.82, 44.88, 43.95, 43.02, 42.08, 41.15, 40.22, 39.30, 38.37, 37.45, 36.53, 35.62, 34.72, 33.82, 32.93, 32.05, 31.17, 30.31, 29.45, 28.60, 27.76, 26.93, 26.10, 25.29, 24.48, 23.69, 22.90, 22.12, 21.34, 20.57, 19.81, 19.05, 18.30, 17.57, 16.84, 16.13, 15.43, 14.75, 14.07, 13.40, 12.75, 12.12, 11.49, 10.89, 10.30, 9.72, 9.17,  8.63, 8.10, 7.60, 7.11, 6.65, 6.21, 5.78, 5.38, 5.00, 4.64, 4.30, 3.99, 3.70, 3.44, 3.20, 2.98, 2.79, 2.62, 2.47, 2.34, 2.22, 2.10, 1.99, 1.88, 1.78, 1.68, 1.59, 1.50, 1.41, 1.32, 1.24, 1.17, 1.09, 1.02, 0.95, 0.89, 0.83, 0.77, 0.71, 0.66, 0.60)
Female
Female <- c(80.94, 80.39, 79.43, 78.44, 77.46, 76.47, 75.47, 74.48, 73.49, 72.50, 71.50, 70.51, 69.52, 68.52, 67.53, 66.54, 65.56, 64.57, 63.59, 62.61, 61.63, 60.66, 59.68, 58.71, 57.74, 56.77, 55.79, 54.82, 53.85, 52.88, 51.92, 50.95, 49.98, 49.02, 48.06, 47.10, 46.14, 45.18, 44.23, 43.27, 42.32, 41.38, 40.43, 39.50, 38.56, 37.63, 36.71, 35.79, 34.88, 33.97, 33.07, 32.18, 31.29, 30.40, 29.52, 28.65, 27.77, 26.91, 26.04, 25.19, 24.34, 23.49, 22.65, 21.83, 21.01, 20.20, 19.40, 18.62, 17.84, 17.08, 16.33, 15.59, 14.87, 14.16, 13.46, 12.77, 12.11, 11.46, 10.83, 10.21, 9.61, 9.03, 8.47, 7.93, 7.41, 6.91, 6.44, 5.99, 5.56, 5.17, 4.80, 4.45, 4.13, 3.84, 3.58, 3.34, 3.13, 2.94, 2.76, 2.60, 2.45, 2.31, 2.17, 2.03, 1.91, 1.79, 1.67, 1.56, 1.45, 1.35, 1.26, 1.17, 1.08, 1.00, 0.92, 0.84, 0.77, 0.71, 0.66, 0.60) ## create Femail column for table
df <- data.frame(Age,Male,Female) ## create data frame
View(df)
?radioButtons
runApp()
runApp()
runApp()
rep("M", rep(1,119))
rep("M", 119)
Gender <- c(rep("M",119),rep("F",119))
Gender <- c(rep("M",120),rep("F",120))
Age <- c(rep(0:119),2) ## create Age column for table
Age <- c(rep(0:119,2)) ## create Age column for table
Age
LifeExp <- Male + Female
LifeExp <- c(Male, Female)
LifeExp
Age <- c(rep(0:119,2)) ## create Age column for table
Gender <- c(rep("M",120),rep("F",120)) ## create gender column
Male <- c(76.10, 75.62, 74.65, 73.67, 72.69, 71.70, 70.71, 69.72, 68.73, 67.74, 66.74, 65.75, 64.76, 63.76, 62.78, 61.80, 60.82, 59.86, 58.90, 57.95, 57.00, 56.06, 55.13, 54.20, 53.27, 52.34, 51.41, 50.48, 49.55, 48.62, 47.68, 46.75, 45.82, 44.88, 43.95, 43.02, 42.08, 41.15, 40.22, 39.30, 38.37, 37.45, 36.53, 35.62, 34.72, 33.82, 32.93, 32.05, 31.17, 30.31, 29.45, 28.60, 27.76, 26.93, 26.10, 25.29, 24.48, 23.69, 22.90, 22.12, 21.34, 20.57, 19.81, 19.05, 18.30, 17.57, 16.84, 16.13, 15.43, 14.75, 14.07, 13.40, 12.75, 12.12, 11.49, 10.89, 10.30, 9.72, 9.17,  8.63, 8.10, 7.60, 7.11, 6.65, 6.21, 5.78, 5.38, 5.00, 4.64, 4.30, 3.99, 3.70, 3.44, 3.20, 2.98, 2.79, 2.62, 2.47, 2.34, 2.22, 2.10, 1.99, 1.88, 1.78, 1.68, 1.59, 1.50, 1.41, 1.32, 1.24, 1.17, 1.09, 1.02, 0.95, 0.89, 0.83, 0.77, 0.71, 0.66, 0.60) ## input male life expectancy values
Female <- c(80.94, 80.39, 79.43, 78.44, 77.46, 76.47, 75.47, 74.48, 73.49, 72.50, 71.50, 70.51, 69.52, 68.52, 67.53, 66.54, 65.56, 64.57, 63.59, 62.61, 61.63, 60.66, 59.68, 58.71, 57.74, 56.77, 55.79, 54.82, 53.85, 52.88, 51.92, 50.95, 49.98, 49.02, 48.06, 47.10, 46.14, 45.18, 44.23, 43.27, 42.32, 41.38, 40.43, 39.50, 38.56, 37.63, 36.71, 35.79, 34.88, 33.97, 33.07, 32.18, 31.29, 30.40, 29.52, 28.65, 27.77, 26.91, 26.04, 25.19, 24.34, 23.49, 22.65, 21.83, 21.01, 20.20, 19.40, 18.62, 17.84, 17.08, 16.33, 15.59, 14.87, 14.16, 13.46, 12.77, 12.11, 11.46, 10.83, 10.21, 9.61, 9.03, 8.47, 7.93, 7.41, 6.91, 6.44, 5.99, 5.56, 5.17, 4.80, 4.45, 4.13, 3.84, 3.58, 3.34, 3.13, 2.94, 2.76, 2.60, 2.45, 2.31, 2.17, 2.03, 1.91, 1.79, 1.67, 1.56, 1.45, 1.35, 1.26, 1.17, 1.08, 1.00, 0.92, 0.84, 0.77, 0.71, 0.66, 0.60) ## input female life expectancy values
LifeExp <- c(Male, Female) ## create life expectancy column
df <- data.frame(Age,Gender,LifeExp) ## create data frame
View(df)
df[ which(df$Gender=='M' & df$Age = 21), ] ## function building block
df[ which(df$Gender=='M' & df$Age == 21), ] ## function building block
df[ which(df$Gender=='M' & df$Age == 21), ]$LifeExp ## function building block
df[ which(df$Gender=='M' & df$Age == 30), ]$LifeExp ## function building block
df[ which(df$Gender=='F' & df$Age == 30), ]$LifeExp ## function building block
df[ which(df$Gender=='F' & df$Age == 32), ]$LifeExp ## function building block
runApp()
library(shiny)
runApp()
deployApp()
deployApp()
library("shinyapps")
deployApp()
deployApp(appName="DevelopingDataProductsCourseraCourseProject")
deployApp(appName="DevelopingDataProductsCourseraCourseProject")
deployApp(appName="DevelopingDataProductsCourseraCourseProject")
library(shiny)
library("shinyapps")
runApp()
deployApp(appName="DevelopingDataProductsCourseraCourseProject")
library(knitr)
rm(list=ls())
library(slidify)
setwd("C:/Users/Default.Default-PC/Documents/R/shiny")
author("DevDataProdCP")
browseURL("index.html")
library(knitr)
slidify('index.Rmd')
install.packages("slidifyLibraries")
library(devtools)
install_github("slidifyLibraries", "ramnathv")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
Sys.Date()
slidify('index.Rmd')
browseURL("index.html")
install_github(c('slidify', 'slidifyLibraries'), 'ramnathv', ref = 'dev')
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
slidify('index.Rmd')
browseURL("index.html")
Thank you for taking the time to listen to my pitch for the Shiny app that was created in conjunction with the Coursera Developing Data Products Course Project. I have created an application that returns the average life expectancy (averaged between male and female genders) of a person in the United States using the input of current age. This app is useful as a quick lookup tool for an average life expectancy without having to search for an actuarial table.
publish(user = "matkins1", repo = "DevelopingDataProductsCoursera")
publish(user = "matkins1", repo = "DevelopingDataProductsCoursera")
publish(user = "https://github.com/matkins1/DevelopingDataProductsCoursera", repo = "DevelopingDataProductsCoursera")
runDeck()
publish(title = 'Developing Data Products Course Project', 'index.html', host = 'rpubs')
publish(title = 'Developing Data Products', 'index.html', host = 'rpubs')
publish(title = 'Developing Data Products', 'index.html', host = 'rpubs')
?publish
?publish
publish(title = 'Developing Data Products', 'index.html', host = 'rpubs')
publish(title = 'Developing Data Products', 'index.html', host = 'rpubs')
runDeck()
runDeck()
slidify('index.Rmd')
browseURL("index.html")
publish(title = 'Developing Data Products', 'index.html', host = 'rpubs')
publish(title = 'Developing Data Products Course Project', 'index.html', host = 'rpubs')
